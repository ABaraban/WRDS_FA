{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# import ray\n",
    "# import os\n",
    "\n",
    "# # Set environment variables for Modin and Ray\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\"\n",
    "# os.environ[\"__MODIN_AUTOIMPORT_PANDAS__\"] = \"1\"\n",
    "# # Look at the Ray documentation with respect to the Ray configuration suited to you most.\n",
    "# ray.init()\n",
    "\n",
    "def fetch_prices_for_dates(cusip_list, date_list):\n",
    "    print(\"Fetching\")\n",
    "    cusip_list_str = \"', '\".join(cusip_list)\n",
    "    date_list_str = \"', '\".join(pd.to_datetime(date_list).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            cusip,\n",
    "            datadate,\n",
    "            ajexdi,\n",
    "            prccd,\n",
    "            trfd\n",
    "        FROM \n",
    "            comp_na_daily_all.secd\n",
    "        WHERE \n",
    "            cusip IN ('{cusip_list_str}') AND\n",
    "            datadate IN ('{date_list_str}')\n",
    "    \"\"\"\n",
    "    return db.raw_sql(query)\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "def first_non_na(row, columns):\n",
    "    for col in columns:\n",
    "        if pd.notna(row[col]):\n",
    "            return row[col]\n",
    "    return None\n",
    "\n",
    "def downcast_numeric_columns(df):\n",
    "    \"\"\"\n",
    "    Downcast numerical columns in a pandas DataFrame to reduce memory usage.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame to downcast.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with downcasted numeric columns.\n",
    "    \"\"\"\n",
    "    # Downcast integer columns\n",
    "    int_cols = df.select_dtypes(include=['int', 'int64']).columns\n",
    "    df[int_cols] = df[int_cols].apply(pd.to_numeric, downcast='integer')\n",
    "    \n",
    "    # Downcast float columns\n",
    "    float_cols = df.select_dtypes(include=['float', 'float64']).columns\n",
    "    df[float_cols] = df[float_cols].apply(pd.to_numeric, downcast='float')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Establish a connection to the WRDS database\n",
    "db = wrds.Connection(wrds_username='asherbaraban')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df = pd.read_pickle(\"raw_insiders_pre_merge.pkl\")\n",
    "# cusip_list = insiders_df['cusipi'].unique().tolist()\n",
    "# trandate_list = insiders_df['trandate'].unique().tolist()\n",
    "\n",
    "# # Generate the additional dates\n",
    "# trandate_6mo_list = (insiders_df['trandate'] + pd.DateOffset(months=6)).unique().tolist()\n",
    "# trandate_6mo_1d_list = (insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=1)).unique().tolist()\n",
    "# trandate_6mo_2d_list = (insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=2)).unique().tolist()\n",
    "\n",
    "# # Combine all date lists\n",
    "# combined_date_list = list(set(trandate_list + trandate_6mo_list + trandate_6mo_1d_list + trandate_6mo_2d_list))\n",
    "# print(len(combined_date_list))\n",
    "# start_time = datetime.now()\n",
    "# print(start_time)\n",
    "# final_prices_df = pd.DataFrame()\n",
    "# date_chunks = list(chunks(combined_date_list, 3000))\n",
    "\n",
    "# for i, date_chunk in enumerate(date_chunks):\n",
    "#     db = wrds.Connection(wrds_username='asherbaraban')\n",
    "#     chunk_start_time = datetime.now()\n",
    "#     print(f\"Processing chunk {i+1}/{len(date_chunks)}\")\n",
    "\n",
    "#     chunk_prices_df = fetch_prices_for_dates(cusip_list, date_chunk)\n",
    "#     chunk_prices_df['datadate'] = pd.to_datetime(chunk_prices_df['datadate'])\n",
    "#     final_prices_df = pd.concat([final_prices_df, chunk_prices_df], ignore_index=True)\n",
    "\n",
    "#     chunk_end_time = datetime.now()\n",
    "#     print(f\"Chunk {i+1} processed in: {chunk_end_time - chunk_start_time}\")\n",
    "#     db.close()\n",
    "\n",
    "# end_time = datetime.now()\n",
    "# print(f\"Data fetched in: {end_time - start_time}\")\n",
    "\n",
    "# # Verify the concatenated DataFrame\n",
    "# print(f\"Total rows fetched: {len(final_prices_df)}\")\n",
    "# print(final_prices_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_prices_df.to_csv(\"raw_prices.csv\", index=False)\n",
    "# final_prices_df.to_pickle('raw_prices.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_prices_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prices_df = pd.read_pickle(\"raw_prices.pkl\")\n",
    "final_prices_df = downcast_numeric_columns(final_prices_df)\n",
    "insiders_df = downcast_numeric_columns(insiders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df['trandate_6mo'] = insiders_df['trandate'] + pd.DateOffset(months=6)\n",
    "insiders_df['trandate_6mo_1'] = insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=1)\n",
    "insiders_df['trandate_6mo_2'] = insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df = insiders_df.merge(final_prices_df,\n",
    "                                left_on=['cusipi', 'trandate'],\n",
    "                                right_on=['cusip', 'datadate'],\n",
    "                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9245190 entries, 0 to 9245189\n",
      "Data columns (total 41 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   dcn             string        \n",
      " 1   seqnum          int16         \n",
      " 2   personid        int32         \n",
      " 3   owner           category      \n",
      " 4   rolecode1       category      \n",
      " 5   rolecode2       category      \n",
      " 6   rolecode3       category      \n",
      " 7   rolecode4       category      \n",
      " 8   cname           category      \n",
      " 9   ticker          category      \n",
      " 10  sector          category      \n",
      " 11  industry        object        \n",
      " 12  trandate        datetime64[ns]\n",
      " 13  tprice          float64       \n",
      " 14  ownership       category      \n",
      " 15  cleanse         category      \n",
      " 16  acqdisp         category      \n",
      " 17  cusipi          object        \n",
      " 18  trandate_6mo    datetime64[ns]\n",
      " 19  trandate_6mo_1  datetime64[ns]\n",
      " 20  trandate_6mo_2  datetime64[ns]\n",
      " 21  cusip           object        \n",
      " 22  datadate        datetime64[ns]\n",
      " 23  ajexdi          float32       \n",
      " 24  prccd           float64       \n",
      " 25  trfd            float64       \n",
      " 26  cusip_6mo       object        \n",
      " 27  datadate_6mo    datetime64[ns]\n",
      " 28  ajexdi_6mo      float32       \n",
      " 29  prccd_6mo       float64       \n",
      " 30  trfd_6mo        float64       \n",
      " 31  cusip_6mo_1     object        \n",
      " 32  datadate_6mo_1  datetime64[ns]\n",
      " 33  ajexdi_6mo_1    float32       \n",
      " 34  prccd_6mo_1     float64       \n",
      " 35  trfd_6mo_1      float64       \n",
      " 36  cusip_6mo_2     object        \n",
      " 37  datadate_6mo_2  datetime64[ns]\n",
      " 38  ajexdi_6mo_2    float32       \n",
      " 39  prccd_6mo_2     float64       \n",
      " 40  trfd_6mo_2      float64       \n",
      "dtypes: category(11), datetime64[ns](8), float32(4), float64(9), int16(1), int32(1), object(6), string(1)\n",
      "memory usage: 2.0+ GB\n"
     ]
    }
   ],
   "source": [
    "insiders_df = insiders_df.merge(final_prices_df,\n",
    "                                left_on=['cusipi', 'trandate_6mo'],\n",
    "                                right_on=['cusip', 'datadate'],\n",
    "                                how='left',\n",
    "                                suffixes=('', '_6mo'))\n",
    "insiders_df = insiders_df.merge(final_prices_df,\n",
    "                                left_on=['cusipi', 'trandate_6mo_1'],\n",
    "                                right_on=['cusip', 'datadate'],\n",
    "                                how='left',\n",
    "                                suffixes=('', '_6mo_1'))\n",
    "insiders_df = insiders_df.merge(final_prices_df,\n",
    "                                left_on=['cusipi', 'trandate_6mo_2'],\n",
    "                                right_on=['cusip', 'datadate'],\n",
    "                                how='left',\n",
    "                                suffixes=('', '_6mo_2'))\n",
    "\n",
    "insiders_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to check in order of priority\n",
    "price_columns = ['prccd_6mo', 'prccd_6mo_1', 'prccd_6mo_2']\n",
    "adjustment_columns = ['ajexdi_6mo', 'ajexdi_6mo_1', 'ajexdi_6mo_2']\n",
    "total_return_columns = ['trfd_6mo', 'trfd_6mo_1', 'trfd_6mo_2']\n",
    "\n",
    "# Apply the function to each row to get the first non-NA value\n",
    "insiders_df['prccd_6mo_consolidated'] = insiders_df.apply(lambda row: first_non_na(row, price_columns), axis=1)\n",
    "insiders_df['ajexdi_6mo_consolidated'] = insiders_df.apply(lambda row: first_non_na(row, adjustment_columns), axis=1)\n",
    "insiders_df['trfd_6mo_consolidated'] = insiders_df.apply(lambda row: first_non_na(row, total_return_columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9245190 entries, 0 to 9245189\n",
      "Data columns (total 47 columns):\n",
      " #   Column                   Dtype         \n",
      "---  ------                   -----         \n",
      " 0   dcn                      string        \n",
      " 1   seqnum                   int16         \n",
      " 2   personid                 int32         \n",
      " 3   owner                    category      \n",
      " 4   rolecode1                category      \n",
      " 5   rolecode2                category      \n",
      " 6   rolecode3                category      \n",
      " 7   rolecode4                category      \n",
      " 8   cname                    category      \n",
      " 9   ticker                   category      \n",
      " 10  sector                   category      \n",
      " 11  industry                 object        \n",
      " 12  trandate                 datetime64[ns]\n",
      " 13  tprice                   float64       \n",
      " 14  ownership                category      \n",
      " 15  cleanse                  category      \n",
      " 16  acqdisp                  category      \n",
      " 17  cusipi                   object        \n",
      " 18  trandate_6mo             datetime64[ns]\n",
      " 19  trandate_6mo_1           datetime64[ns]\n",
      " 20  trandate_6mo_2           datetime64[ns]\n",
      " 21  cusip                    object        \n",
      " 22  datadate                 datetime64[ns]\n",
      " 23  ajexdi                   float32       \n",
      " 24  prccd                    float64       \n",
      " 25  trfd                     float64       \n",
      " 26  cusip_6mo                object        \n",
      " 27  datadate_6mo             datetime64[ns]\n",
      " 28  ajexdi_6mo               float32       \n",
      " 29  prccd_6mo                float64       \n",
      " 30  trfd_6mo                 float64       \n",
      " 31  cusip_6mo_1              object        \n",
      " 32  datadate_6mo_1           datetime64[ns]\n",
      " 33  ajexdi_6mo_1             float32       \n",
      " 34  prccd_6mo_1              float64       \n",
      " 35  trfd_6mo_1               float64       \n",
      " 36  cusip_6mo_2              object        \n",
      " 37  datadate_6mo_2           datetime64[ns]\n",
      " 38  ajexdi_6mo_2             float32       \n",
      " 39  prccd_6mo_2              float64       \n",
      " 40  trfd_6mo_2               float64       \n",
      " 41  prccd_6mo_consolidated   float64       \n",
      " 42  ajexdi_6mo_consolidated  float64       \n",
      " 43  trfd_6mo_consolidated    float64       \n",
      " 44  prccd_adjusted_begin     float64       \n",
      " 45  prccd_adjusted_end       float64       \n",
      " 46  total_return_6mo         float64       \n",
      "dtypes: category(11), datetime64[ns](8), float32(4), float64(15), int16(1), int32(1), object(6), string(1)\n",
      "memory usage: 2.4+ GB\n"
     ]
    }
   ],
   "source": [
    "insiders_df['prccd_adjusted_begin'] = insiders_df['prccd'] / insiders_df['ajexdi']\n",
    "insiders_df['prccd_adjusted_end'] = insiders_df['prccd_6mo_consolidated'] / insiders_df['ajexdi_6mo_consolidated']\n",
    "\n",
    "insiders_df['total_return_6mo'] = (\n",
    "    (insiders_df['prccd_adjusted_end'] * insiders_df['trfd_6mo_consolidated']) /\n",
    "    (insiders_df['prccd_adjusted_begin'] * insiders_df['trfd'])\n",
    ") - 1\n",
    "\n",
    "insiders_df.info()\n",
    "insiders_df.to_pickle(\"merged_prices_insiders.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insiders_df.to_pickle(\"merged_prices_insiders.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n",
      "Fetching\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 60632 entries, (Timestamp('1988-11-16 00:00:00'), '81369Y100') to (Timestamp('2003-06-11 00:00:00'), '81369Y803')\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   price_adj  60632 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 691.9 KB\n"
     ]
    }
   ],
   "source": [
    "insiders_df = pd.read_pickle(\"merged_prices_insiders.pkl\")\n",
    "insiders_df['trandate'] = pd.to_datetime(insiders_df['trandate'])\n",
    "insiders_df['trandate_6mo'] = pd.to_datetime(insiders_df['trandate_6mo'])\n",
    "insiders_df['trandate_6mo_1'] = pd.to_datetime(insiders_df['trandate_6mo_1'])\n",
    "insiders_df['trandate_6mo_2'] = pd.to_datetime(insiders_df['trandate_6mo_2'])\n",
    "insiders_df = downcast_numeric_columns(insiders_df)\n",
    "\n",
    "object_cols = ['owner', 'rolecode1', 'rolecode2', 'rolecode3', 'rolecode4', 'cname', 'ticker', 'sector', 'ownership', 'cleanse', 'acqdisp', 'cusipi']\n",
    "for col in object_cols:\n",
    "    insiders_df[col] = insiders_df[col].astype('category')\n",
    "insiders_df['dcn'] = insiders_df['dcn'].astype('string')\n",
    "insiders_df['seqnum'] = pd.to_numeric(insiders_df['seqnum'], downcast='integer')\n",
    "insiders_df['personid'] = pd.to_numeric(insiders_df['personid'], downcast='integer')\n",
    "\n",
    "db = wrds.Connection(wrds_username='asherbaraban')\n",
    "sector_etfs = {\n",
    "    1: \"XLF\",  # Finance\n",
    "    2: \"XLV\",  # Healthcare\n",
    "    3: \"IYK\",  # Consumer Non-Durable\n",
    "    4: \"XLY\",  # Consumer Services\n",
    "    5: \"XHB\",  # Consumer Durables\n",
    "    6: \"XLE\",  # Energy\n",
    "    7: \"IYT\",  # Transportation\n",
    "    8: \"XLK\",  # Technology\n",
    "    9: \"XLB\",  # Basic Industries\n",
    "    10: \"XLI\",  # Capital Goods\n",
    "    11: \"XLU\",  # Public Utilities\n",
    "    99: \"VTI\",  # Miscellaneous\n",
    "    0: \"VTI\",  # Not Classified\n",
    "    \"XX\": \"VTI\",  # Not Classified\n",
    "}\n",
    "\n",
    "benchmark_tickers = sector_etfs.values()\n",
    "tickers_placeholder = ', '.join(f\"'{ticker}'\" for ticker in benchmark_tickers)\n",
    "\n",
    "query = f\"\"\"\n",
    "        SELECT \n",
    "            cusip,\n",
    "            datadate,\n",
    "            ajexdi,\n",
    "            trfd,\n",
    "            prccd,\n",
    "            tic\n",
    "        FROM \n",
    "            comp_na_daily_all.secd\n",
    "        WHERE \n",
    "            tic IN ({tickers_placeholder}) AND\n",
    "            datadate = '2023-10-02'\n",
    "    \"\"\"\n",
    "prices = db.raw_sql(query)\n",
    "\n",
    "ticker_to_cusip = prices.set_index('tic')['cusip'].to_dict()\n",
    "# Generate the additional dates\n",
    "trandate_list = insiders_df['trandate'].unique().tolist()\n",
    "trandate_6mo_list = (insiders_df['trandate'] + pd.DateOffset(months=6)).unique().tolist()\n",
    "trandate_6mo_1d_list = (insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=1)).unique().tolist()\n",
    "trandate_6mo_2d_list = (insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=2)).unique().tolist()\n",
    "\n",
    "# Combine all date lists\n",
    "combined_date_list = list(set(trandate_list + trandate_6mo_list + trandate_6mo_1d_list + trandate_6mo_2d_list))\n",
    "\n",
    "# Now query the right dates to get total returns for all of the right intervals \n",
    "etf_prices = fetch_prices_for_dates(ticker_to_cusip.values(), combined_date_list)\n",
    "etf_prices['datadate'] = pd.to_datetime(insiders_df['datadate'])\n",
    "insiders_df['sector_ticker'] = insiders_df['sector'].map(sector_etfs)\n",
    "insiders_df['sector_cusip'] = insiders_df['sector_ticker'].map(ticker_to_cusip)\n",
    "etf_prices['cusip'] = etf_prices['cusip'].astype('category')\n",
    "etf_prices.dropna(subset=['datadate'], inplace=True)\n",
    "\n",
    "etf_prices['price_adj'] = (etf_prices['prccd'] * etf_prices['trfd']) / etf_prices['ajexdi']\n",
    "etf_prices.drop(columns = ['prccd', 'trfd', 'ajexdi'], inplace=True)\n",
    "\n",
    "etf_prices.rename(columns={'datadate': 'date', 'cusip': 'sector_cusip'}, inplace=True)\n",
    "etf_prices.set_index(['date', 'sector_cusip'], inplace=True)\n",
    "etf_prices.sort_index(inplace=True)\n",
    "etf_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9245190 entries, 0 to 9245189\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   dcn               string        \n",
      " 1   seqnum            int16         \n",
      " 2   personid          int32         \n",
      " 3   owner             category      \n",
      " 4   rolecode1         category      \n",
      " 5   rolecode2         category      \n",
      " 6   rolecode3         category      \n",
      " 7   rolecode4         category      \n",
      " 8   ticker            category      \n",
      " 9   sector            category      \n",
      " 10  trandate          datetime64[ns]\n",
      " 11  ownership         category      \n",
      " 12  cleanse           category      \n",
      " 13  acqdisp           category      \n",
      " 14  cusipi            category      \n",
      " 15  trandate_6mo      datetime64[ns]\n",
      " 16  trandate_6mo_1    datetime64[ns]\n",
      " 17  trandate_6mo_2    datetime64[ns]\n",
      " 18  cusip             object        \n",
      " 19  total_return_6mo  float32       \n",
      " 20  sector_cusip      category      \n",
      "dtypes: category(12), datetime64[ns](4), float32(1), int16(1), int32(1), object(1), string(1)\n",
      "memory usage: 673.4+ MB\n"
     ]
    }
   ],
   "source": [
    "insiders_df['sector_cusip'] = insiders_df['sector_cusip'].astype('category')\n",
    "insiders_df['sector_ticker'] = insiders_df['sector_ticker'].astype('category')\n",
    "insiders_df['industry'] = insiders_df['industry'].astype('category')\n",
    "insiders_df['cusip_6mo'] = insiders_df['cusip_6mo'].astype('string')\n",
    "\n",
    "substrings = ['trfd', 'ajexdi', 'prccd', 'datadate', 'cusip_', 'sector_ticker', 'industry', 'cname', 'tprice']\n",
    "\n",
    "# Identify columns to drop based on the substrings\n",
    "columns_to_drop = [col for col in insiders_df.columns if any(sub in col for sub in substrings)]\n",
    "\n",
    "# Drop the identified columns inplace\n",
    "insiders_df.drop(columns=columns_to_drop, inplace=True)\n",
    "insiders_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dcn', 'seqnum', 'personid', 'owner', 'rolecode1', 'rolecode2',\n",
      "       'rolecode3', 'rolecode4', 'ticker', 'sector', 'date', 'ownership',\n",
      "       'cleanse', 'acqdisp', 'cusipi', 'trandate_6mo', 'trandate_6mo_1',\n",
      "       'trandate_6mo_2', 'cusip', 'total_return_6mo', 'sector_cusip'],\n",
      "      dtype='object')\n",
      "A completed\n",
      "B completed\n",
      "C completed\n",
      "All merges completed\n"
     ]
    }
   ],
   "source": [
    "# Merge with trandate_6mo\n",
    "insiders_df.rename(columns={'trandate': 'date'}, inplace=True)\n",
    "print(insiders_df.columns)\n",
    "insiders_df.set_index(['date', 'sector_cusip'], inplace=True)\n",
    "insiders_df = insiders_df.merge(etf_prices, left_index=True, right_index=True, how='left', suffixes=('', '_sec'))\n",
    "insiders_df.reset_index(inplace=True)\n",
    "insiders_df.rename(columns={'date': 'trandate'}, inplace=True)\n",
    "print(\"A completed\")\n",
    "\n",
    "# Merge with trandate_6mo\n",
    "insiders_df.rename(columns={'trandate_6mo': 'date'}, inplace=True)\n",
    "insiders_df.set_index(['date', 'sector_cusip'], inplace=True)\n",
    "insiders_df = insiders_df.merge(etf_prices, left_index=True, right_index=True, how='left', suffixes=('', '_sec_6mo'))\n",
    "insiders_df.reset_index(inplace=True)\n",
    "insiders_df.rename(columns={'date': 'trandate_6mo'}, inplace=True)\n",
    "print(\"B completed\")\n",
    "\n",
    "# Merge with trandate_6mo_1\n",
    "insiders_df.rename(columns={'trandate_6mo_1': 'date'}, inplace=True)\n",
    "insiders_df.set_index(['date', 'sector_cusip'], inplace=True)\n",
    "insiders_df = insiders_df.merge(etf_prices, left_index=True, right_index=True, how='left', suffixes=('', '_sec_6mo_1'))\n",
    "insiders_df.reset_index(inplace=True)\n",
    "insiders_df.rename(columns={'date': 'trandate_6mo_1'}, inplace=True)\n",
    "print(\"C completed\")\n",
    "\n",
    "# Merge with trandate_6mo_2\n",
    "insiders_df.rename(columns={'trandate_6mo_2': 'date'}, inplace=True)\n",
    "insiders_df.set_index(['date', 'sector_cusip'], inplace=True)\n",
    "insiders_df = insiders_df.merge(etf_prices, left_index=True, right_index=True, how='left', suffixes=('', '_sec_6mo_2'))\n",
    "insiders_df.reset_index(inplace=True)\n",
    "insiders_df.rename(columns={'date': 'trandate_6mo_2'}, inplace=True)\n",
    "print(\"All merges completed\")\n",
    "\n",
    "# Save the merged dataframe\n",
    "insiders_df.to_pickle(\"post_sector.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9245190 entries, 0 to 9245189\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   trandate_6mo_2       datetime64[ns]\n",
      " 1   sector_cusip         category      \n",
      " 2   trandate_6mo_1       datetime64[ns]\n",
      " 3   trandate_6mo         datetime64[ns]\n",
      " 4   trandate             datetime64[ns]\n",
      " 5   dcn                  string        \n",
      " 6   seqnum               int16         \n",
      " 7   personid             int32         \n",
      " 8   owner                category      \n",
      " 9   rolecode1            category      \n",
      " 10  rolecode2            category      \n",
      " 11  rolecode3            category      \n",
      " 12  rolecode4            category      \n",
      " 13  ticker               category      \n",
      " 14  sector               category      \n",
      " 15  ownership            category      \n",
      " 16  cleanse              category      \n",
      " 17  acqdisp              category      \n",
      " 18  cusipi               category      \n",
      " 19  cusip                object        \n",
      " 20  total_return_6mo     float32       \n",
      " 21  price_adj            float64       \n",
      " 22  price_adj_sec_6mo    float64       \n",
      " 23  price_adj_sec_6mo_1  float64       \n",
      " 24  price_adj_sec_6mo_2  float64       \n",
      "dtypes: category(12), datetime64[ns](4), float32(1), float64(4), int16(1), int32(1), object(1), string(1)\n",
      "memory usage: 955.6+ MB\n"
     ]
    }
   ],
   "source": [
    "insiders_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxxx\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming insiders_df is already defined and has the column 'trandate'\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xxx' is not defined"
     ]
    }
   ],
   "source": [
    "xxx\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Assuming insiders_df is already defined and has the column 'trandate'\n",
    "insiders_df['trandate_year'] = insiders_df['trandate'].dt.year\n",
    "\n",
    "# Group by the extracted year and calculate the mean total return\n",
    "annual_return = insiders_df.groupby(['trandate_year', 'acqdisp'])['total_return_6mo'].mean().reset_index()\n",
    "annual_return = annual_return[annual_return['acqdisp'] == 'A']\n",
    "# Create a line plot of the average total return by year\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(annual_return['trandate_year'], annual_return['total_return_6mo'], marker='o', linestyle='-')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Total Return (6 Months)')\n",
    "plt.title('Average 6-Month Total Return by Year')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
