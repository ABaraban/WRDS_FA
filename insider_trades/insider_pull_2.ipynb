{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "import pandas as pds\n",
    "\n",
    "# Establish a connection to the WRDS database\n",
    "db = wrds.Connection(wrds_username='asherbaraban')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch insiders data\n",
    "insiders_df = db.raw_sql(f\"\"\"\n",
    "    SELECT\n",
    "        dcn,\n",
    "        seqnum,\n",
    "        personid,\n",
    "        owner,\n",
    "        rolecode1,\n",
    "        rolecode2,\n",
    "        rolecode3,\n",
    "        rolecode4,\n",
    "        cname,\n",
    "        ticker,\n",
    "        sector,\n",
    "        industry,\n",
    "        trandate,\n",
    "        tprice,\n",
    "        ownership,\n",
    "        cleanse,\n",
    "        acqdisp,\n",
    "        CONCAT(cusip6, cusip2, cusipx) AS cusipI\n",
    "    FROM tr_insiders.table1\n",
    "    WHERE \n",
    "        formtype = '4' AND\n",
    "        cleanse IN ('R', 'H') AND\n",
    "        trancode IS NOT NULL AND\n",
    "        acqdisp IS NOT NULL AND\n",
    "        cusip6 IS NOT NULL AND\n",
    "        cusip2 IS NOT NULL AND\n",
    "        cusipx IS NOT NULL\n",
    "\"\"\")\n",
    "insiders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = insiders_df.copy()\n",
    "insiders_df['trandate'] = pd.to_datetime(insiders_df['trandate'])\n",
    "object_cols = ['owner', 'rolecode1', 'rolecode2', 'rolecode3', 'rolecode4', 'cname', 'ticker', 'sector', 'ownership', 'cleanse', 'acqdisp', 'cusipi']\n",
    "for col in object_cols:\n",
    "    insiders_df[col] = insiders_df[col].astype('category')\n",
    "insiders_df['dcn'] = insiders_df['dcn'].astype('string')\n",
    "insiders_df['seqnum'] = pd.to_numeric(insiders_df['seqnum'], downcast='integer')\n",
    "insiders_df['personid'] = pd.to_numeric(insiders_df['personid'], downcast='integer')\n",
    "\n",
    "insiders_df.to_csv(\"raw_insiders_pre_merge.csv\", index=False)\n",
    "\n",
    "\n",
    "comparison = original_df.compare(insiders_df)\n",
    "\n",
    "# Check for differences\n",
    "if comparison.empty:\n",
    "    print(\"No information loss detected in all columns.\")\n",
    "else:\n",
    "    print(\"Information loss detected:\")\n",
    "    print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df = pd.read_csv(\"raw_insiders_pre_merge.csv\")\n",
    "insiders_df['trandate'] = pd.to_datetime(insiders_df['trandate'])\n",
    "object_cols = ['owner', 'rolecode1', 'rolecode2', 'rolecode3', 'rolecode4', 'cname', 'ticker', 'sector', 'ownership', 'cleanse', 'acqdisp', 'cusipi']\n",
    "for col in object_cols:\n",
    "    insiders_df[col] = insiders_df[col].astype('category')\n",
    "insiders_df['dcn'] = insiders_df['dcn'].astype('string')\n",
    "insiders_df['seqnum'] = pd.to_numeric(insiders_df['seqnum'], downcast='integer')\n",
    "insiders_df['personid'] = pd.to_numeric(insiders_df['personid'], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def fetch_prices_for_date(cusip_list, date):\n",
    "    cusip_list_str = \"', '\".join(cusip_list)\n",
    "    date_str = pd.to_datetime(date).strftime('%Y-%m-%d')\n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            cusip,\n",
    "            datadate,\n",
    "            prccd,\n",
    "            ajexdi,\n",
    "            trfd\n",
    "        FROM \n",
    "            comp_na_daily_all.secd\n",
    "        WHERE \n",
    "            cusip IN ('{cusip_list_str}') AND\n",
    "            datadate = '{date_str}'\n",
    "    \"\"\"\n",
    "    return db.raw_sql(query)\n",
    "\n",
    "def fetch_prices_for_dates(cusip_list, date_list):\n",
    "    print(\"Fetching\")\n",
    "    cusip_list_str = \"', '\".join(cusip_list)\n",
    "    date_list_str = \"', '\".join(pd.to_datetime(date_list).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            cusip,\n",
    "            datadate,\n",
    "            prccd,\n",
    "            ajexdi,\n",
    "            trfd\n",
    "        FROM \n",
    "            comp_na_daily_all.secd\n",
    "        WHERE \n",
    "            cusip IN ('{cusip_list_str}') AND\n",
    "            datadate IN ('{date_list_str}')\n",
    "    \"\"\"\n",
    "    return db.raw_sql(query)\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "cusip_list = insiders_df['cusipi'].unique().tolist()\n",
    "trandate_list = insiders_df['trandate'].unique().tolist()\n",
    "\n",
    "\n",
    "# Generate the additional dates\n",
    "trandate_6mo_list = (insiders_df['trandate'] + pd.DateOffset(months=6)).unique().tolist()\n",
    "trandate_6mo_1d_list = (insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=1)).unique().tolist()\n",
    "trandate_6mo_2d_list = (insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=2)).unique().tolist()\n",
    "\n",
    "# Combine all date lists\n",
    "combined_date_list = list(set(trandate_list + trandate_6mo_list + trandate_6mo_1d_list + trandate_6mo_2d_list))\n",
    "print(len(combined_date_list))\n",
    "start_time = datetime.now()\n",
    "print(start_time)\n",
    "final_prices_df = pd.DataFrame()\n",
    "date_chunks = list(chunks(combined_date_list, 3000))\n",
    "\n",
    "for i, date_chunk in enumerate(date_chunks):\n",
    "    chunk_start_time = datetime.now()\n",
    "    print(f\"Processing chunk {i+1}/{len(date_chunks)}\")\n",
    "\n",
    "    chunk_prices_df = fetch_prices_for_dates(cusip_list, date_chunk)\n",
    "    chunk_prices_df['datadate'] = pd.to_datetime(chunk_prices_df['datadate'])\n",
    "    final_prices_df = pd.concat([final_prices_df, chunk_prices_df], ignore_index=True)\n",
    "\n",
    "    chunk_end_time = datetime.now()\n",
    "    print(f\"Chunk {i+1} processed in: {chunk_end_time - chunk_start_time}\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"Data fetched in: {end_time - start_time}\")\n",
    "\n",
    "# Verify the concatenated DataFrame\n",
    "print(f\"Total rows fetched: {len(final_prices_df)}\")\n",
    "print(final_prices_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prices_df.to_csv(\"raw_prices.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df['trandate_6mo'] = insiders_df['trandate'] + pd.DateOffset(months=6)\n",
    "insiders_df['trandate_6mo_1'] = insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=1)\n",
    "insiders_df['trandate_6mo_2'] = insiders_df['trandate'] + pd.DateOffset(months=6) +  pd.DateOffset(days=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df = insiders_df.merge(final_prices_df,\n",
    "                                left_on=['cusipi', 'trandate'],\n",
    "                                right_on=['cusip', 'datadate'],\n",
    "                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df = insiders_df.merge(final_prices_df,\n",
    "                                left_on=['cusipi', 'trandate_6mo'],\n",
    "                                right_on=['cusip', 'datadate'],\n",
    "                                how='left',\n",
    "                                suffixes=('', '_6mo'))\n",
    "insiders_df = insiders_df.merge(final_prices_df,\n",
    "                                left_on=['cusipi', 'trandate_6mo_1'],\n",
    "                                right_on=['cusip', 'datadate'],\n",
    "                                how='left',\n",
    "                                suffixes=('', '_6mo_1'))\n",
    "insiders_df = insiders_df.merge(final_prices_df,\n",
    "                                left_on=['cusipi', 'trandate_6mo_2'],\n",
    "                                right_on=['cusip', 'datadate'],\n",
    "                                how='left',\n",
    "                                suffixes=('', '_6mo_2'))\n",
    "\n",
    "insiders_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_non_na(row, columns):\n",
    "    for col in columns:\n",
    "        if pd.notna(row[col]):\n",
    "            return row[col]\n",
    "    return None\n",
    "\n",
    "# List of columns to check in order of priority\n",
    "price_columns = ['prccd_6mo', 'prccd_6mo_1', 'prccd_6mo_2']\n",
    "adjustment_columns = ['ajexdi_6mo', 'ajexdi_6mo_1', 'ajexdi_6mo_2']\n",
    "total_return_columns = ['trfd_6mo', 'trfd_6mo_1', 'trfd_6mo_2']\n",
    "\n",
    "# Apply the function to each row to get the first non-NA value\n",
    "insiders_df['prccd_6mo_consolidated'] = insiders_df.apply(lambda row: first_non_na(row, price_columns), axis=1)\n",
    "insiders_df['ajexdi_6mo_consolidated'] = insiders_df.apply(lambda row: first_non_na(row, adjustment_columns), axis=1)\n",
    "insiders_df['trfd_6mo_consolidated'] = insiders_df.apply(lambda row: first_non_na(row, total_return_columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df['prccd_adjusted_begin'] = insiders_df['prccd'] / insiders_df['ajexdi']\n",
    "insiders_df['prccd_adjusted_end'] = insiders_df['prccd_6mo_consolidated'] / insiders_df['ajexdi_6mo_consolidated']\n",
    "\n",
    "insiders_df['total_return_6mo'] = (\n",
    "    (insiders_df['prccd_adjusted_end'] * insiders_df['trfd_6mo_consolidated']) /\n",
    "    (insiders_df['prccd_adjusted_begin'] * insiders_df['trfd'])\n",
    ") - 1\n",
    "\n",
    "insiders_df.head()\n",
    "insiders_df.to_csv(\"merged_prices_insiders.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Assuming insiders_df is already defined and has the column 'trandate'\n",
    "insiders_df['trandate_year'] = insiders_df['trandate'].dt.year\n",
    "\n",
    "# Group by the extracted year and calculate the mean total return\n",
    "annual_return = insiders_df.groupby(['trandate_year', 'acqdisp'])['total_return_6mo'].mean().reset_index()\n",
    "annual_return = annual_return[annual_return['acqdisp'] == 'A']\n",
    "# Create a line plot of the average total return by year\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(annual_return['trandate_year'], annual_return['total_return_6mo'], marker='o', linestyle='-')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Total Return (6 Months)')\n",
    "plt.title('Average 6-Month Total Return by Year')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df['industry'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_all_na = insiders_df[['cusip', 'cusip_6mo', 'cusip_6mo_1', 'cusip_6mo_2']].isna().all(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_all_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming insiders_df is already defined\n",
    "# You can find the rows where all specified columns are NA\n",
    "na_rows = insiders_df[insiders_df[['cusip', 'cusip_6mo', 'cusip_6mo_1', 'cusip_6mo_2']].isna().all(axis=1)]\n",
    "\n",
    "# Display the rows\n",
    "print(na_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rows[['cusipi', 'ticker', 'trandate', 'cname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rows['trandate_year'] = na_rows['trandate'].dt.year\n",
    "\n",
    "# Calculate the distribution of years\n",
    "year_distribution = na_rows['trandate_year'].value_counts().sort_index() \n",
    "year_distribution.plot(kind='bar', figsize=(10, 6))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Years for trandate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_prices(cusip_list):\n",
    "    print(\"Fetching\")\n",
    "    cusip_list_str = \"', '\".join(cusip_list)\n",
    "    # date_list_str = \"', '\".join(pd.to_datetime(date_list).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            cusip,\n",
    "            datadate,\n",
    "            prccd,\n",
    "            ajexdi,\n",
    "            trfd,\n",
    "            tic,\n",
    "            conm\n",
    "        FROM \n",
    "            comp_na_daily_all.secd\n",
    "        WHERE \n",
    "            tic IN ('{cusip_list_str}')\n",
    "    \"\"\"\n",
    "    return db.raw_sql(query)\n",
    "\n",
    "x = fetch_prices([\"IFCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['datadate'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insiders_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
